{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from report import Report\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml(\n",
    "    'mnist_784',\n",
    "    version=1,\n",
    "    return_X_y=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    train_size=60000,\n",
    "    test_size=10000,\n",
    "    shuffle=False\n",
    ")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalizer = X_train.max(axis=0)\n",
    "X_train_normalizer[X_train_normalizer == 0] = 1\n",
    "X_test_normalizer = X_test.max(axis=0)\n",
    "X_test_normalizer[X_test_normalizer == 0] = 1\n",
    "\n",
    "X_train_encoded = X_train / X_train_normalizer\n",
    "X_test_encoded = X_test / X_test_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=10\n",
    "y_train_encoded = np.eye(classes)[y_train.astype(int)]\n",
    "y_test_encoded = np.eye(classes)[y_test.astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=28,\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate_init=0.1,\n",
    "    max_iter=100,\n",
    "    random_state=123,\n",
    "    verbose=True,\n",
    "    momentum=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.29350776\n",
      "Iteration 2, loss = 1.55759886\n",
      "Iteration 3, loss = 1.33713655\n",
      "Iteration 4, loss = 1.22567012\n",
      "Iteration 5, loss = 1.28045206\n",
      "Iteration 6, loss = 1.28156916\n",
      "Iteration 7, loss = 1.12445355\n",
      "Iteration 8, loss = 1.09730823\n",
      "Iteration 9, loss = 1.11028361\n",
      "Iteration 10, loss = 1.04571306\n",
      "Iteration 11, loss = 1.06865743\n",
      "Iteration 12, loss = 0.99488684\n",
      "Iteration 13, loss = 0.99746207\n",
      "Iteration 14, loss = 0.98375742\n",
      "Iteration 15, loss = 1.00370731\n",
      "Iteration 16, loss = 0.97148752\n",
      "Iteration 17, loss = 1.00505064\n",
      "Iteration 18, loss = 1.00348687\n",
      "Iteration 19, loss = 0.92924669\n",
      "Iteration 20, loss = 0.89325510\n",
      "Iteration 21, loss = 0.88885215\n",
      "Iteration 22, loss = 0.92148068\n",
      "Iteration 23, loss = 0.97507587\n",
      "Iteration 24, loss = 0.92669127\n",
      "Iteration 25, loss = 0.90138509\n",
      "Iteration 26, loss = 0.87283312\n",
      "Iteration 27, loss = 0.85121440\n",
      "Iteration 28, loss = 0.83106134\n",
      "Iteration 29, loss = 0.84012850\n",
      "Iteration 30, loss = 0.86440830\n",
      "Iteration 31, loss = 0.85148965\n",
      "Iteration 32, loss = 0.89463506\n",
      "Iteration 33, loss = 0.83809152\n",
      "Iteration 34, loss = 0.86072139\n",
      "Iteration 35, loss = 0.96193385\n",
      "Iteration 36, loss = 0.90949528\n",
      "Iteration 37, loss = 0.84250851\n",
      "Iteration 38, loss = 0.86882515\n",
      "Iteration 39, loss = 0.89185751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=28,\n",
       "              learning_rate_init=0.1, max_iter=100, momentum=0.1,\n",
       "              random_state=123, solver='sgd', verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_train = Report(\n",
    "    np.argmax(np.array(pred_train), axis=1),\n",
    "    y_train.astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8708833333333333\n",
      "Recall: {0: 0.4845531285353755, 1: 0.4903620833018369, 2: 0.46071687183200577, 3: 0.4531263937204531, 4: 0.4694878314565928, 5: 0.43460575719649563, 6: 0.4848089144250022, 7: 0.47317524386141946, 8: 0.4391833604907505, 9: 0.4523108083225925}\n",
      "Precision: {0: 0.4776938915579959, 1: 0.482233125185846, 2: 0.4526858769121309, 3: 0.45757521167357235, 4: 0.4691470054446461, 5: 0.4553600699377117, 6: 0.4618893588786597, 7: 0.4668934616661135, 8: 0.4608267122598813, 9: 0.46454236006051436}\n",
      "F1: {0: 0.24054953125675033, 1: 0.24313181664855144, 2: 0.2283330342723847, 3: 0.22766996817998475, 4: 0.23465867828612927, 5: 0.22237045733496985, 6: 0.23653584777437986, 7: 0.2350066822586034, 8: 0.22487239890066746, 9: 0.22917249743446214}\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', report_train.accuracy())\n",
    "print('Recall:', report_train.recall())\n",
    "print('Precision:', report_train.precision())\n",
    "print('F1:', report_train.f1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5568</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>14</td>\n",
       "      <td>179</td>\n",
       "      <td>38</td>\n",
       "      <td>67</td>\n",
       "      <td>68</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6487</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "      <td>36</td>\n",
       "      <td>62</td>\n",
       "      <td>16</td>\n",
       "      <td>88</td>\n",
       "      <td>160</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135</td>\n",
       "      <td>51</td>\n",
       "      <td>5090</td>\n",
       "      <td>314</td>\n",
       "      <td>32</td>\n",
       "      <td>124</td>\n",
       "      <td>88</td>\n",
       "      <td>167</td>\n",
       "      <td>130</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>139</td>\n",
       "      <td>5080</td>\n",
       "      <td>8</td>\n",
       "      <td>357</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>179</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>5170</td>\n",
       "      <td>62</td>\n",
       "      <td>98</td>\n",
       "      <td>68</td>\n",
       "      <td>43</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>211</td>\n",
       "      <td>6</td>\n",
       "      <td>4167</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>399</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>289</td>\n",
       "      <td>26</td>\n",
       "      <td>157</td>\n",
       "      <td>205</td>\n",
       "      <td>5569</td>\n",
       "      <td>7</td>\n",
       "      <td>143</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>91</td>\n",
       "      <td>163</td>\n",
       "      <td>34</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>5627</td>\n",
       "      <td>41</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>74</td>\n",
       "      <td>134</td>\n",
       "      <td>180</td>\n",
       "      <td>34</td>\n",
       "      <td>130</td>\n",
       "      <td>22</td>\n",
       "      <td>56</td>\n",
       "      <td>4582</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>60</td>\n",
       "      <td>351</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>106</td>\n",
       "      <td>4913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9\n",
       "0  5568     2    55    45    14   179    38    67    68    52\n",
       "1     1  6487    46    45    36    62    16    88   160    24\n",
       "2   135    51  5090   314    32   124    88   167   130    23\n",
       "3    28    44   139  5080     8   357    11    60   179   116\n",
       "4    25    10    85     7  5170    62    98    68    43   282\n",
       "5    55    37    10   211     6  4167    74     3   399    22\n",
       "6    71     8   289    26   157   205  5569     7   143    13\n",
       "7    12    24    91   163    34    54     0  5627    41   379\n",
       "8    24    74   134   180    34   130    22    56  4582   125\n",
       "9     4     5    19    60   351    81     2   122   106  4913"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    report_train.confusion(),\n",
    "    index=list(set(y_test)).sort(),\n",
    "    columns=list(set(y_test)).sort()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_test = Report(\n",
    "    np.argmax(np.array(pred_test), axis=1),\n",
    "    y_test.astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8745\n",
      "Recall: {0: 0.48825065274151436, 1: 0.49443207126948774, 2: 0.4685890834191555, 3: 0.45902517407605786, 4: 0.47004856988667026, 5: 0.4322087842138765, 6: 0.4790647090810223, 7: 0.47037609479649667, 8: 0.44183381088825213, 9: 0.44772851669403396}\n",
      "Precision: {0: 0.4748603351955307, 1: 0.488556338028169, 2: 0.46381243628950053, 3: 0.4544008483563097, 4: 0.4655264564404062, 5: 0.45357381429525717, 6: 0.4666313559322034, 7: 0.4670076726342711, 8: 0.45702430349733253, 9: 0.4653014789533561}\n",
      "F1: {0: 0.24073120494335737, 1: 0.2457383218950631, 2: 0.23309426229508196, 3: 0.22835065281108444, 4: 0.23388829215896886, 5: 0.2213168187744459, 6: 0.23638314998658438, 7: 0.23434291581108832, 8: 0.2246503496503496, 9: 0.2281729428172943}\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', report_test.accuracy())\n",
    "print('Recall:', report_test.recall())\n",
    "print('Precision:', report_test.precision())\n",
    "print('F1:', report_test.f1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>935</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1110</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>910</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>871</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>679</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>913</td>\n",
       "      <td>9</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>771</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>14</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1    2    3    4    5    6    7    8    9\n",
       "0  935     0   11    7    3   26   14    9   16   13\n",
       "1    0  1110    7    1    3    3    2   14   17    5\n",
       "2   15     3  910   41    2   16   16   35   11    3\n",
       "3    3     4   21  857    1   79    2   15   29   18\n",
       "4    1     0    9    0  871   12   27    5   10   65\n",
       "5    8     3    0   34    1  679   10    2   75    6\n",
       "6   14     3   29    2   31   23  881    1   22    1\n",
       "7    2     0   12   30    6    9    0  913    9   61\n",
       "8    1    11   31   35    4   32    5    7  771   19\n",
       "9    1     1    2    3   60   13    1   27   14  818"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    report_test.confusion(),\n",
    "    index=list(set(y_test)).sort(),\n",
    "    columns=list(set(y_test)).sort()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=28,\n",
    "    activation='logistic',\n",
    "    solver='sgd',\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.1,\n",
    "    max_iter=500,\n",
    "    random_state=123,\n",
    "    verbose=True,\n",
    "    momentum=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.29350776\n",
      "Iteration 2, loss = 1.55759886\n",
      "Iteration 3, loss = 1.33713655\n",
      "Iteration 4, loss = 1.22567012\n",
      "Iteration 5, loss = 1.28045206\n",
      "Iteration 6, loss = 1.28156916\n",
      "Iteration 7, loss = 1.12445355\n",
      "Iteration 8, loss = 1.09730823\n",
      "Iteration 9, loss = 1.11028361\n",
      "Iteration 10, loss = 1.04571306\n",
      "Iteration 11, loss = 1.06865743\n",
      "Iteration 12, loss = 0.99488684\n",
      "Iteration 13, loss = 0.99746207\n",
      "Iteration 14, loss = 0.98375742\n",
      "Iteration 15, loss = 1.00370731\n",
      "Iteration 16, loss = 0.97148752\n",
      "Iteration 17, loss = 1.00505064\n",
      "Iteration 18, loss = 1.00348687\n",
      "Iteration 19, loss = 0.92924669\n",
      "Iteration 20, loss = 0.89325510\n",
      "Iteration 21, loss = 0.88885215\n",
      "Iteration 22, loss = 0.92148068\n",
      "Iteration 23, loss = 0.97507587\n",
      "Iteration 24, loss = 0.92669127\n",
      "Iteration 25, loss = 0.90138509\n",
      "Iteration 26, loss = 0.87283312\n",
      "Iteration 27, loss = 0.85121440\n",
      "Iteration 28, loss = 0.83106134\n",
      "Iteration 29, loss = 0.84012850\n",
      "Iteration 30, loss = 0.86440830\n",
      "Iteration 31, loss = 0.85148965\n",
      "Iteration 32, loss = 0.89463506\n",
      "Iteration 33, loss = 0.83809152\n",
      "Iteration 34, loss = 0.86072139\n",
      "Iteration 35, loss = 0.96193385\n",
      "Iteration 36, loss = 0.90949528\n",
      "Iteration 37, loss = 0.84250851\n",
      "Iteration 38, loss = 0.86882515\n",
      "Iteration 39, loss = 0.89185751\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 40, loss = 0.79452821\n",
      "Iteration 41, loss = 0.77718638\n",
      "Iteration 42, loss = 0.76979117\n",
      "Iteration 43, loss = 0.75642270\n",
      "Iteration 44, loss = 0.75202249\n",
      "Iteration 45, loss = 0.74781992\n",
      "Iteration 46, loss = 0.74115995\n",
      "Iteration 47, loss = 0.74623909\n",
      "Iteration 48, loss = 0.73633550\n",
      "Iteration 49, loss = 0.73858403\n",
      "Iteration 50, loss = 0.74176985\n",
      "Iteration 51, loss = 0.73866376\n",
      "Iteration 52, loss = 0.72905741\n",
      "Iteration 53, loss = 0.72187387\n",
      "Iteration 54, loss = 0.72676511\n",
      "Iteration 55, loss = 0.71717244\n",
      "Iteration 56, loss = 0.71822474\n",
      "Iteration 57, loss = 0.72504607\n",
      "Iteration 58, loss = 0.71813251\n",
      "Iteration 59, loss = 0.70628185\n",
      "Iteration 60, loss = 0.70577922\n",
      "Iteration 61, loss = 0.71197027\n",
      "Iteration 62, loss = 0.70202517\n",
      "Iteration 63, loss = 0.71086865\n",
      "Iteration 64, loss = 0.70548005\n",
      "Iteration 65, loss = 0.70144884\n",
      "Iteration 66, loss = 0.69750199\n",
      "Iteration 67, loss = 0.69770879\n",
      "Iteration 68, loss = 0.69710419\n",
      "Iteration 69, loss = 0.69718026\n",
      "Iteration 70, loss = 0.70841434\n",
      "Iteration 71, loss = 0.69980643\n",
      "Iteration 72, loss = 0.69913937\n",
      "Iteration 73, loss = 0.68766760\n",
      "Iteration 74, loss = 0.69320832\n",
      "Iteration 75, loss = 0.69553768\n",
      "Iteration 76, loss = 0.68953857\n",
      "Iteration 77, loss = 0.69930923\n",
      "Iteration 78, loss = 0.69171949\n",
      "Iteration 79, loss = 0.69275211\n",
      "Iteration 80, loss = 0.69041146\n",
      "Iteration 81, loss = 0.69114711\n",
      "Iteration 82, loss = 0.68707869\n",
      "Iteration 83, loss = 0.68288880\n",
      "Iteration 84, loss = 0.68267856\n",
      "Iteration 85, loss = 0.68103064\n",
      "Iteration 86, loss = 0.67226632\n",
      "Iteration 87, loss = 0.67713731\n",
      "Iteration 88, loss = 0.67922732\n",
      "Iteration 89, loss = 0.67353283\n",
      "Iteration 90, loss = 0.66832997\n",
      "Iteration 91, loss = 0.67655212\n",
      "Iteration 92, loss = 0.68750786\n",
      "Iteration 93, loss = 0.67828501\n",
      "Iteration 94, loss = 0.67132767\n",
      "Iteration 95, loss = 0.67250237\n",
      "Iteration 96, loss = 0.67913036\n",
      "Iteration 97, loss = 0.67388087\n",
      "Iteration 98, loss = 0.66468816\n",
      "Iteration 99, loss = 0.66634445\n",
      "Iteration 100, loss = 0.66938355\n",
      "Iteration 101, loss = 0.67093189\n",
      "Iteration 102, loss = 0.67140102\n",
      "Iteration 103, loss = 0.66896574\n",
      "Iteration 104, loss = 0.66903291\n",
      "Iteration 105, loss = 0.66729904\n",
      "Iteration 106, loss = 0.66455643\n",
      "Iteration 107, loss = 0.66495252\n",
      "Iteration 108, loss = 0.66057881\n",
      "Iteration 109, loss = 0.66116280\n",
      "Iteration 110, loss = 0.66207690\n",
      "Iteration 111, loss = 0.65960870\n",
      "Iteration 112, loss = 0.66749373\n",
      "Iteration 113, loss = 0.66127909\n",
      "Iteration 114, loss = 0.66112063\n",
      "Iteration 115, loss = 0.65938312\n",
      "Iteration 116, loss = 0.65110248\n",
      "Iteration 117, loss = 0.65662141\n",
      "Iteration 118, loss = 0.65402037\n",
      "Iteration 119, loss = 0.65581001\n",
      "Iteration 120, loss = 0.65574895\n",
      "Iteration 121, loss = 0.65239955\n",
      "Iteration 122, loss = 0.64629709\n",
      "Iteration 123, loss = 0.65326431\n",
      "Iteration 124, loss = 0.64550022\n",
      "Iteration 125, loss = 0.65098202\n",
      "Iteration 126, loss = 0.65207736\n",
      "Iteration 127, loss = 0.65236026\n",
      "Iteration 128, loss = 0.65264662\n",
      "Iteration 129, loss = 0.64671514\n",
      "Iteration 130, loss = 0.65351714\n",
      "Iteration 131, loss = 0.65749466\n",
      "Iteration 132, loss = 0.65859175\n",
      "Iteration 133, loss = 0.66141186\n",
      "Iteration 134, loss = 0.64895782\n",
      "Iteration 135, loss = 0.65269524\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 136, loss = 0.66431236\n",
      "Iteration 137, loss = 0.65846752\n",
      "Iteration 138, loss = 0.65549018\n",
      "Iteration 139, loss = 0.64945067\n",
      "Iteration 140, loss = 0.64540428\n",
      "Iteration 141, loss = 0.64393233\n",
      "Iteration 142, loss = 0.64227226\n",
      "Iteration 143, loss = 0.63825463\n",
      "Iteration 144, loss = 0.63365738\n",
      "Iteration 145, loss = 0.63351894\n",
      "Iteration 146, loss = 0.63234215\n",
      "Iteration 147, loss = 0.63120787\n",
      "Iteration 148, loss = 0.62980317\n",
      "Iteration 149, loss = 0.62965637\n",
      "Iteration 150, loss = 0.62887725\n",
      "Iteration 151, loss = 0.62786295\n",
      "Iteration 152, loss = 0.62740811\n",
      "Iteration 153, loss = 0.62893713\n",
      "Iteration 154, loss = 0.62678285\n",
      "Iteration 155, loss = 0.62598311\n",
      "Iteration 156, loss = 0.62681564\n",
      "Iteration 157, loss = 0.62469326\n",
      "Iteration 158, loss = 0.62341352\n",
      "Iteration 159, loss = 0.62094284\n",
      "Iteration 160, loss = 0.62005625\n",
      "Iteration 161, loss = 0.61981542\n",
      "Iteration 162, loss = 0.61837045\n",
      "Iteration 163, loss = 0.61715364\n",
      "Iteration 164, loss = 0.61765764\n",
      "Iteration 165, loss = 0.61790398\n",
      "Iteration 166, loss = 0.61841730\n",
      "Iteration 167, loss = 0.61838781\n",
      "Iteration 168, loss = 0.61651570\n",
      "Iteration 169, loss = 0.61619292\n",
      "Iteration 170, loss = 0.61569212\n",
      "Iteration 171, loss = 0.61664583\n",
      "Iteration 172, loss = 0.61580578\n",
      "Iteration 173, loss = 0.61390591\n",
      "Iteration 174, loss = 0.61363431\n",
      "Iteration 175, loss = 0.61265291\n",
      "Iteration 176, loss = 0.61258966\n",
      "Iteration 177, loss = 0.61284096\n",
      "Iteration 178, loss = 0.61247138\n",
      "Iteration 179, loss = 0.61236908\n",
      "Iteration 180, loss = 0.61188385\n",
      "Iteration 181, loss = 0.61197424\n",
      "Iteration 182, loss = 0.61336851\n",
      "Iteration 183, loss = 0.61080913\n",
      "Iteration 184, loss = 0.61150558\n",
      "Iteration 185, loss = 0.61068863\n",
      "Iteration 186, loss = 0.61118726\n",
      "Iteration 187, loss = 0.61073365\n",
      "Iteration 188, loss = 0.60936992\n",
      "Iteration 189, loss = 0.60931304\n",
      "Iteration 190, loss = 0.60904367\n",
      "Iteration 191, loss = 0.60966459\n",
      "Iteration 192, loss = 0.61021918\n",
      "Iteration 193, loss = 0.60972107\n",
      "Iteration 194, loss = 0.60948453\n",
      "Iteration 195, loss = 0.60681897\n",
      "Iteration 196, loss = 0.60642472\n",
      "Iteration 197, loss = 0.60721783\n",
      "Iteration 198, loss = 0.60775515\n",
      "Iteration 199, loss = 0.60826058\n",
      "Iteration 200, loss = 0.60642152\n",
      "Iteration 201, loss = 0.60593516\n",
      "Iteration 202, loss = 0.60466684\n",
      "Iteration 203, loss = 0.60579409\n",
      "Iteration 204, loss = 0.60430660\n",
      "Iteration 205, loss = 0.60384316\n",
      "Iteration 206, loss = 0.60401130\n",
      "Iteration 207, loss = 0.60462961\n",
      "Iteration 208, loss = 0.60506737\n",
      "Iteration 209, loss = 0.60278767\n",
      "Iteration 210, loss = 0.60367668\n",
      "Iteration 211, loss = 0.60393816\n",
      "Iteration 212, loss = 0.60364898\n",
      "Iteration 213, loss = 0.60227510\n",
      "Iteration 214, loss = 0.60186089\n",
      "Iteration 215, loss = 0.60085037\n",
      "Iteration 216, loss = 0.60058521\n",
      "Iteration 217, loss = 0.60129011\n",
      "Iteration 218, loss = 0.60103500\n",
      "Iteration 219, loss = 0.60112302\n",
      "Iteration 220, loss = 0.60123436\n",
      "Iteration 221, loss = 0.60132310\n",
      "Iteration 222, loss = 0.60162696\n",
      "Iteration 223, loss = 0.60214416\n",
      "Iteration 224, loss = 0.60573695\n",
      "Iteration 225, loss = 0.60397662\n",
      "Iteration 226, loss = 0.60141525\n",
      "Iteration 227, loss = 0.60029584\n",
      "Iteration 228, loss = 0.60003094\n",
      "Iteration 229, loss = 0.59977404\n",
      "Iteration 230, loss = 0.60049119\n",
      "Iteration 231, loss = 0.59984912\n",
      "Iteration 232, loss = 0.59766915\n",
      "Iteration 233, loss = 0.59635501\n",
      "Iteration 234, loss = 0.59912398\n",
      "Iteration 235, loss = 0.59964171\n",
      "Iteration 236, loss = 0.59775567\n",
      "Iteration 237, loss = 0.59595790\n",
      "Iteration 238, loss = 0.59761993\n",
      "Iteration 239, loss = 0.59587415\n",
      "Iteration 240, loss = 0.59704225\n",
      "Iteration 241, loss = 0.59599387\n",
      "Iteration 242, loss = 0.59598437\n",
      "Iteration 243, loss = 0.59601294\n",
      "Iteration 244, loss = 0.59749599\n",
      "Iteration 245, loss = 0.59885004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 246, loss = 0.59874195\n",
      "Iteration 247, loss = 0.59702968\n",
      "Iteration 248, loss = 0.59549742\n",
      "Iteration 249, loss = 0.59486623\n",
      "Iteration 250, loss = 0.59527015\n",
      "Iteration 251, loss = 0.59454938\n",
      "Iteration 252, loss = 0.59242551\n",
      "Iteration 253, loss = 0.59380225\n",
      "Iteration 254, loss = 0.59255425\n",
      "Iteration 255, loss = 0.59449970\n",
      "Iteration 256, loss = 0.59440370\n",
      "Iteration 257, loss = 0.59396826\n",
      "Iteration 258, loss = 0.59190325\n",
      "Iteration 259, loss = 0.59341610\n",
      "Iteration 260, loss = 0.59468715\n",
      "Iteration 261, loss = 0.59399022\n",
      "Iteration 262, loss = 0.59201186\n",
      "Iteration 263, loss = 0.59017027\n",
      "Iteration 264, loss = 0.59004800\n",
      "Iteration 265, loss = 0.58979097\n",
      "Iteration 266, loss = 0.59248743\n",
      "Iteration 267, loss = 0.59368650\n",
      "Iteration 268, loss = 0.59133850\n",
      "Iteration 269, loss = 0.59226874\n",
      "Iteration 270, loss = 0.59391651\n",
      "Iteration 271, loss = 0.59486211\n",
      "Iteration 272, loss = 0.59351835\n",
      "Iteration 273, loss = 0.59108869\n",
      "Iteration 274, loss = 0.59115965\n",
      "Iteration 275, loss = 0.59105530\n",
      "Iteration 276, loss = 0.59045455\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 277, loss = 0.58859769\n",
      "Iteration 278, loss = 0.58778619\n",
      "Iteration 279, loss = 0.58735577\n",
      "Iteration 280, loss = 0.58721155\n",
      "Iteration 281, loss = 0.58697716\n",
      "Iteration 282, loss = 0.58656401\n",
      "Iteration 283, loss = 0.58670819\n",
      "Iteration 284, loss = 0.58661789\n",
      "Iteration 285, loss = 0.58642227\n",
      "Iteration 286, loss = 0.58623724\n",
      "Iteration 287, loss = 0.58606600\n",
      "Iteration 288, loss = 0.58587498\n",
      "Iteration 289, loss = 0.58579678\n",
      "Iteration 290, loss = 0.58603894\n",
      "Iteration 291, loss = 0.58556381\n",
      "Iteration 292, loss = 0.58561438\n",
      "Iteration 293, loss = 0.58562122\n",
      "Iteration 294, loss = 0.58538138\n",
      "Iteration 295, loss = 0.58540476\n",
      "Iteration 296, loss = 0.58528728\n",
      "Iteration 297, loss = 0.58525265\n",
      "Iteration 298, loss = 0.58515960\n",
      "Iteration 299, loss = 0.58516343\n",
      "Iteration 300, loss = 0.58500421\n",
      "Iteration 301, loss = 0.58496978\n",
      "Iteration 302, loss = 0.58482320\n",
      "Iteration 303, loss = 0.58485034\n",
      "Iteration 304, loss = 0.58481831\n",
      "Iteration 305, loss = 0.58474199\n",
      "Iteration 306, loss = 0.58469173\n",
      "Iteration 307, loss = 0.58467122\n",
      "Iteration 308, loss = 0.58477272\n",
      "Iteration 309, loss = 0.58461503\n",
      "Iteration 310, loss = 0.58459426\n",
      "Iteration 311, loss = 0.58457446\n",
      "Iteration 312, loss = 0.58455674\n",
      "Iteration 313, loss = 0.58454807\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 314, loss = 0.58450792\n",
      "Iteration 315, loss = 0.58448513\n",
      "Iteration 316, loss = 0.58447775\n",
      "Iteration 317, loss = 0.58447222\n",
      "Iteration 318, loss = 0.58446812\n",
      "Iteration 319, loss = 0.58446476\n",
      "Iteration 320, loss = 0.58446178\n",
      "Iteration 321, loss = 0.58445887\n",
      "Iteration 322, loss = 0.58445604\n",
      "Iteration 323, loss = 0.58445323\n",
      "Iteration 324, loss = 0.58445057\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 325, loss = 0.58444628\n",
      "Iteration 326, loss = 0.58444570\n",
      "Iteration 327, loss = 0.58444514\n",
      "Iteration 328, loss = 0.58444459\n",
      "Iteration 329, loss = 0.58444405\n",
      "Iteration 330, loss = 0.58444349\n",
      "Iteration 331, loss = 0.58444295\n",
      "Iteration 332, loss = 0.58444238\n",
      "Iteration 333, loss = 0.58444185\n",
      "Iteration 334, loss = 0.58444127\n",
      "Iteration 335, loss = 0.58444072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 336, loss = 0.58443983\n",
      "Iteration 337, loss = 0.58443971\n",
      "Iteration 338, loss = 0.58443960\n",
      "Iteration 339, loss = 0.58443948\n",
      "Iteration 340, loss = 0.58443937\n",
      "Iteration 341, loss = 0.58443926\n",
      "Iteration 342, loss = 0.58443914\n",
      "Iteration 343, loss = 0.58443903\n",
      "Iteration 344, loss = 0.58443891\n",
      "Iteration 345, loss = 0.58443880\n",
      "Iteration 346, loss = 0.58443868\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 347, loss = 0.58443850\n",
      "Iteration 348, loss = 0.58443848\n",
      "Iteration 349, loss = 0.58443845\n",
      "Iteration 350, loss = 0.58443843\n",
      "Iteration 351, loss = 0.58443841\n",
      "Iteration 352, loss = 0.58443839\n",
      "Iteration 353, loss = 0.58443836\n",
      "Iteration 354, loss = 0.58443834\n",
      "Iteration 355, loss = 0.58443832\n",
      "Iteration 356, loss = 0.58443829\n",
      "Iteration 357, loss = 0.58443827\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 358, loss = 0.58443823\n",
      "Iteration 359, loss = 0.58443823\n",
      "Iteration 360, loss = 0.58443822\n",
      "Iteration 361, loss = 0.58443822\n",
      "Iteration 362, loss = 0.58443821\n",
      "Iteration 363, loss = 0.58443821\n",
      "Iteration 364, loss = 0.58443820\n",
      "Iteration 365, loss = 0.58443820\n",
      "Iteration 366, loss = 0.58443820\n",
      "Iteration 367, loss = 0.58443819\n",
      "Iteration 368, loss = 0.58443819\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Learning rate too small. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=28,\n",
       "              learning_rate='adaptive', learning_rate_init=0.1, max_iter=500,\n",
       "              momentum=0.1, random_state=123, solver='sgd', verbose=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_train = Report(\n",
    "    np.argmax(np.array(pred_train), axis=1),\n",
    "    y_train.astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9071666666666667\n",
      "Recall: {0: 0.49276355228226426, 1: 0.4912082107010792, 2: 0.4713867447431461, 3: 0.4658011675524963, 4: 0.4851956291857596, 5: 0.4556682397831108, 6: 0.4859723790497698, 7: 0.48021239525429354, 8: 0.4631124977060011, 9: 0.4583447145588637}\n",
      "Precision: {0: 0.48397678526368915, 1: 0.4912082107010792, 2: 0.4730656219392752, 3: 0.4652336611260987, 4: 0.4660572202471644, 5: 0.4739425587467363, 6: 0.47881899871630296, 7: 0.4758303189740217, 8: 0.46649413069599777, 9: 0.4789268385500904}\n",
      "F1: {0: 0.24416532292285498, 1: 0.2456041053505396, 2: 0.2361123455692827, 3: 0.23275862068965517, 4: 0.23771695017701408, 5: 0.2323128903450394, 6: 0.24118458487800673, 7: 0.23900565718297068, 8: 0.23239858175622785, 9: 0.23420489438913186}\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', report_train.accuracy())\n",
    "print('Recall:', report_train.recall())\n",
    "print('Precision:', report_train.precision())\n",
    "print('F1:', report_train.f1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5754</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>87</td>\n",
       "      <td>61</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6509</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>46</td>\n",
       "      <td>5313</td>\n",
       "      <td>251</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>46</td>\n",
       "      <td>102</td>\n",
       "      <td>62</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>36</td>\n",
       "      <td>97</td>\n",
       "      <td>5346</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>201</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>113</td>\n",
       "      <td>13</td>\n",
       "      <td>5506</td>\n",
       "      <td>64</td>\n",
       "      <td>111</td>\n",
       "      <td>98</td>\n",
       "      <td>54</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>15</td>\n",
       "      <td>184</td>\n",
       "      <td>7</td>\n",
       "      <td>4538</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>129</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>149</td>\n",
       "      <td>5595</td>\n",
       "      <td>5</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>22</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>5788</td>\n",
       "      <td>48</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>121</td>\n",
       "      <td>111</td>\n",
       "      <td>30</td>\n",
       "      <td>176</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>5047</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>46</td>\n",
       "      <td>173</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "      <td>5034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4     5     6     7     8     9\n",
       "0  5754     2    61    30    18    87    61    24    57    41\n",
       "1     0  6509    22    18    22    19     6    36    95    15\n",
       "2    20    46  5313   251    12    40    46   102    62    26\n",
       "3    15    36    97  5346     2   267     4    68   201   109\n",
       "4    21    13   113    13  5506    64   111    98    54   315\n",
       "5    33    34    15   184     7  4538    52    18   129    27\n",
       "6    35     5   130    32    50   149  5595     5    87     2\n",
       "7    10    26    78   100    22    42     0  5788    48   262\n",
       "8    32    66   121   111    30   176    41    30  5047   118\n",
       "9     3     5     8    46   173    39     2    96    71  5034"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    report_train.confusion(),\n",
    "    index=list(set(y_test)).sort(),\n",
    "    columns=list(set(y_test)).sort()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_test = Report(\n",
    "    np.argmax(np.array(pred_test), axis=1),\n",
    "    y_test.astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.899\n",
      "Recall: {0: 0.49432404540763675, 1: 0.49352967425256583, 2: 0.4702258726899384, 3: 0.4647588765235824, 4: 0.4855945521215296, 5: 0.44561839651957735, 6: 0.4799131378935939, 7: 0.4728205128205128, 8: 0.46068660022148394, 9: 0.4575268817204301}\n",
      "Precision: {0: 0.47876061969015493, 1: 0.4917741218319253, 2: 0.47658688865764826, 3: 0.4565330557001562, 4: 0.46466165413533833, 5: 0.4720210664911126, 6: 0.4793926247288503, 7: 0.47354904982023627, 8: 0.45941468801766977, 9: 0.4778214486243683}\n",
      "F1: {0: 0.2432089362782432, 1: 0.24632516703786192, 2: 0.2366925064599483, 3: 0.2303046218487395, 4: 0.23744877049180327, 5: 0.22921994884910488, 6: 0.23982637004883342, 7: 0.23659225044906335, 8: 0.2300248824993088, 9: 0.23372699807745123}\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', report_test.accuracy())\n",
    "print('Recall:', report_test.recall())\n",
    "print('Precision:', report_test.precision())\n",
    "print('F1:', report_test.f1())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>958</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1106</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>916</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>927</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>717</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>884</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>922</td>\n",
       "      <td>10</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>832</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1    2    3    4    5    6    7    8    9\n",
       "0  958     0   12   11    3   15   18    8   11    7\n",
       "1    0  1106    6    1    3    1    1    9   14    2\n",
       "2    2     4  916   36    2    5    8   29    4    0\n",
       "3    1     7   24  877    0   72    2   15   33   13\n",
       "4    0     0   16    4  927    8   27   10   15   61\n",
       "5    5     5    0   28    1  717    9    1   27    9\n",
       "6    7     3   16    2    9   18  884    1   18    2\n",
       "7    4     1   12   21    4   13    1  922   10   37\n",
       "8    3     9   28   24    5   36    8    7  832   27\n",
       "9    0     0    2    6   28    7    0   26   10  851"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    report_test.confusion(),\n",
    "    index=list(set(y_test)).sort(),\n",
    "    columns=list(set(y_test)).sort()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
